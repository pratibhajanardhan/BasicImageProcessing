{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN on CIFAR dataset with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yogesh/lab_activities/Deep_Learning_42/CNN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change directory\n",
    "PATH = os.getcwd() \n",
    "print (PATH)\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras model module\n",
    "\n",
    "    Import the Sequential model type from Keras. This is simply a linear stack of neural network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yogesh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yogesh/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras core layers\n",
    "    \n",
    "    Import the \"core\" layers from Keras. These are the layers that are used in almost any neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras CNN layers\n",
    "\n",
    "     Import the CNN layers from Keras. These are the convolutional layers that will help us efficiently train on image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import convolutional, pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilities\n",
    "\n",
    "    import some utilities. This will help us transform our data later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the CIFAR image data from `keras.datasets`\n",
    "\n",
    "\n",
    "* CIFAR-10 is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170434560/170498071 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    " \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns:\n",
    "\n",
    "    2 tuples:\n",
    "            x_train, x_test: uint8 array of image data with shape (num_samples, 32, 32, 3).\n",
    "            y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples, 1).\n",
    "\n",
    "Arguments:\n",
    "\n",
    "    path: if you do not have the index file locally (at '~/.keras/datasets/' + path), it will be downloaded to this location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the shape of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras backends\n",
    "\n",
    "Keras is a model-level library, providing high-level building blocks for developing deep learning models. It does not handle itself low-level operations such as tensor products, convolutions and so on. Instead, it relies on a specialized, well-optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. Rather than picking one single tensor library and making the implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras.\n",
    "\n",
    "At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.\n",
    "\n",
    "    TensorFlow is an open-source symbolic tensor manipulation framework developed by Google, Inc.\n",
    "    Theano is an open-source symbolic tensor manipulation framework developed by LISA/MILA Lab at Université de Montréal.\n",
    "    CNTK is an open-source, commercial-grade toolkit for deep learning developed by Microsoft.\n",
    "\n",
    "In the future, some more backend options may be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Switching from one backend to another\n",
    "\n",
    "If you have run Keras at least once, you will find the Keras configuration file at:\n",
    "\n",
    "$HOME/.keras/keras.json\n",
    "\n",
    "If it isn't there, you can create it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras.json details\n",
    "\n",
    "{\n",
    "\n",
    "    \"image_data_format\": \"channels_last\",\n",
    "\n",
    "    \"epsilon\": 1e-07,\n",
    "        \n",
    "    \"floatx\": \"float32\",\n",
    "    \n",
    "    \"backend\": \"tensorflow\"\n",
    "\n",
    "}\n",
    "\n",
    "You can change these settings by editing $HOME/.keras/keras.json.\n",
    "\n",
    "    image_data_format: string, either \"channels_last\" or \"channels_first\". It specifies which data format convention Keras will follow. (keras.backend.image_data_format() returns it.)\n",
    "        For 2D data (e.g. image), \"channels_last\" assumes (rows, cols, channels) while \n",
    "                                  \"channels_first\" assumes (channels, rows, cols).\n",
    "        For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n",
    "                     \"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\n",
    "    epsilon: float, a numeric fuzzing constant used to avoid dividing by zero in some operations.\n",
    "    \n",
    "    floatx: string, \"float16\", \"float32\", or \"float64\". Default float precision.\n",
    "    \n",
    "    backend: string, \"tensorflow\", \"theano\", or \"cntk\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "from keras import backend\n",
    "\n",
    "print (backend.backend())\n",
    "print (backend.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess input data for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape input data\n",
    "\n",
    "    When using the tensorflow backend, you must explicitly declare a dimension for the depth of the input image. \n",
    "    E.g. a full-color image with all 3 RGB channels will have a depth of 3 such as (n, width, height, channel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " print X_train's dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our data type to float32 and normalize our data values to the range [0, 1]\n",
    "\n",
    "Note: Max value X_train/X_test can take is 255, so it is divided by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the shape of our class label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have 10 different classes, but it looks like we only have a 1-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " [4]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [7]\n",
      " [8]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "print (y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Convert 1-dimensional class arrays to 10-dimensional class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take another look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the input layer\n",
    "\n",
    "CNN input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(convolutional.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### 2D convolution layer (e.g. spatial convolution over images).\n",
    "\n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n",
    "\n",
    "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(28, 28, 1) for 28x28 gray pictures in data_format=\"channels_last\".\n",
    "\n",
    "First parameters correspond to the number of convolution filters \n",
    "\n",
    "Next 2 parameters correspond to kernal size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add more layers to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(convolutional.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(pooling.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(core.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout\n",
    "\n",
    "    This is a method for regularizing our model in order to prevent overfitting. \n",
    "\n",
    "MaxPooling2D \n",
    "\n",
    "    Is a way to reduce the number of parameters in our model by sliding a 2x2 pooling filter across the previous layer and taking the max of the 4 values in the 2x2 filter.\n",
    "\n",
    "So far, for model parameters, we've added two Convolution layers. To complete our model architecture, let's add a fully connected layer and then the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(core.Flatten())\n",
    "model.add(core.Dense(128, activation='relu'))\n",
    "model.add(core.Dropout(0.5))\n",
    "model.add(core.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Dense layers, the first parameter is the output size of the layer. Keras automatically handles the connections between layers.\n",
    "\n",
    "Note that the final layer has an output size of 10, corresponding to the 10 classes of digits.\n",
    "\n",
    "Also note that the weights from the Convolution layers must be flattened (made 1-dimensional) before passing them to the fully connected Dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model by providing the loss function and the optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 814,378\n",
      "Trainable params: 814,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "80s - loss: 1.5430 - acc: 0.4435\n",
      "Epoch 2/2\n",
      "89s - loss: 1.2157 - acc: 0.5706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0000b0d5f8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0549163019180299, 0.6317]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.96057607e-03 6.18038757e-04 3.03653758e-02 ... 1.13424417e-02\n",
      "  3.42388102e-03 8.98917112e-03]\n",
      " [1.20685101e-01 7.80714571e-01 6.62122038e-05 ... 6.80314116e-08\n",
      "  9.06425416e-02 7.83650205e-03]\n",
      " [3.31039876e-01 3.34322810e-01 2.02969238e-02 ... 1.00379367e-03\n",
      "  1.91191450e-01 1.03523836e-01]\n",
      " ...\n",
      " [2.11372133e-03 3.87668442e-05 9.30316225e-02 ... 8.86757299e-02\n",
      "  1.64373399e-04 4.57310089e-04]\n",
      " [7.90476874e-02 6.07554495e-01 2.70472392e-02 ... 8.24164879e-03\n",
      "  9.61851981e-03 3.95110138e-02]\n",
      " [5.91633070e-05 3.15426296e-05 2.07308936e-03 ... 9.37291682e-01\n",
      "  2.33186961e-06 3.00148604e-05]]\n"
     ]
    }
   ],
   "source": [
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred_class = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6317"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[769,  24,  87,  15,  12,   6,  14,  12,  23,  38],\n",
       "       [ 39, 783,  10,  13,   5,   3,  14,  12,   6, 115],\n",
       "       [ 89,   5, 474,  64, 109, 127,  78,  38,   3,  13],\n",
       "       [ 30,  11,  85, 422,  71, 224,  97,  39,   4,  17],\n",
       "       [ 50,   4, 113,  75, 533,  43,  73, 100,   6,   3],\n",
       "       [ 17,   3,  76, 145,  42, 610,  32,  67,   6,   2],\n",
       "       [  7,   6,  71,  59,  46,  35, 762,  11,   1,   2],\n",
       "       [ 17,   1,  36,  40,  56, 102,   7, 731,   1,   9],\n",
       "       [277,  83,  20,  31,   8,   8,  10,   5, 515,  43],\n",
       "       [ 62, 108,  16,  14,  14,   8,  13,  36,  11, 718]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "\n",
    "    https://keras.io/\n",
    "    https://elitedatascience.com\n",
    "    http://scikit-learn.org/stable/modules/classes.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
